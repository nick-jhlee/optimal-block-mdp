{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy.linalg as LA\n",
    "from scipy.optimize import minimize\n",
    "from math import inf\n",
    "from sklearn.preprocessing import normalize\n",
    "from pyclustering.cluster.kmedians import kmedians\n",
    "from itertools import permutations\n",
    "\n",
    "from tqdm import tqdm\n",
    "from Synthetic import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def count_transition(x, a, y, trajectories):\n",
    "    cnt = 0\n",
    "    H = len(trajectories[0])\n",
    "    for trajectory in trajectories:\n",
    "        cnt += sum(1 for i in range(H - 2) if i % 2 == 0 and trajectory[i:i + 3] == [x, a, y])\n",
    "    return cnt\n",
    "\n",
    "def count_visitation(x, a, trajectories):\n",
    "    cnt = 0\n",
    "    H = len(trajectories[0])\n",
    "    for trajectory in trajectories:\n",
    "        cnt += sum(1 for i in range(H - 1) if i % 2 == 0 and trajectory[i:i + 2] == [x, a])\n",
    "    return cnt\n",
    "\n",
    "\n",
    "def count_transition_latent(s, a, v, trajectories, f):\n",
    "    cnt = 0\n",
    "    H = len(trajectories[0])\n",
    "    for trajectory in trajectories:\n",
    "        cnt += sum(1 for i in range(H - 2) if i % 2 == 0 and f[trajectory[i]] == s and trajectory[i + 1] == a and f[\n",
    "            trajectory[i + 2]] == v)\n",
    "    return cnt\n",
    "\n",
    "\n",
    "def count_transition_mixed1(x, a, s, trajectories, f):\n",
    "    cnt = 0\n",
    "    H = len(trajectories[0])\n",
    "    for trajectory in trajectories:\n",
    "        cnt += sum(1 for i in range(H - 2) if i % 2 == 0 and trajectory[i] == x and trajectory[i + 1] == a and f[\n",
    "            trajectory[i + 2]] == s)\n",
    "    return cnt\n",
    "\n",
    "\n",
    "def count_transition_mixed2(s, a, x, trajectories, f):\n",
    "    cnt = 0\n",
    "    H = len(trajectories[0])\n",
    "    for trajectory in trajectories:\n",
    "        cnt += sum(1 for i in range(H - 2) if\n",
    "                   i % 2 == 0 and f[trajectory[i]] == s and trajectory[i + 1] == a and trajectory[i + 2] == x)\n",
    "    return cnt\n",
    "\n",
    "\n",
    "def low_rank(N, r=1):\n",
    "    U, S, V = LA.svd(N, full_matrices=False)\n",
    "    Nr = np.zeros((len(U), len(V)))\n",
    "    for i in range(r):\n",
    "        Nr += S[i] * np.outer(U.T[i], V[i])\n",
    "    return Nr\n",
    "\n",
    "\n",
    "def count_error(f, f_1, perm, n):\n",
    "    cnt = 0\n",
    "    for x in range(n):\n",
    "        if f[x] != perm[f_1[x]]:\n",
    "            cnt += 1\n",
    "    return cnt\n",
    "\n",
    "\n",
    "def error_rate(f, f_1, n, S):\n",
    "    error = n\n",
    "    for perm_ in permutations(range(S)):\n",
    "        perm = {}\n",
    "        for s in range(S):\n",
    "            perm[s] = perm_[s]\n",
    "        error = min(error, count_error(f, f_1, perm, n))\n",
    "\n",
    "    return error / n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 2 10 100\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "\n",
    "A = 2\n",
    "H = 100\n",
    "T =  int(np.ceil(n*A*np.log(n*A)) / H)\n",
    "\n",
    "env_config = {'n' : n, 'H' : H, 'S:': 2, 'A' : A, 'ps': [np.array([[3 / 4, 1 / 4], [1 / 4, 3 / 4]]), np.array([[1 / 2, 1 / 2], [1 / 2, 1 / 2]])], 'qs': 'uniform'}\n",
    "env = Synthetic(env_config)\n",
    "# true clusters\n",
    "f = {}\n",
    "for s in range(env.S):\n",
    "    cluster = env.partitions[s]\n",
    "    for x in range(cluster.start, cluster.start + cluster.n):\n",
    "        f[x] = s\n",
    "# obtain trajectories\n",
    "trajectories = generate_trajectories(T, env)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 26.63it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 26.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate after initial clustering is  0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n, S, A, H = env.n, env.S, env.A, env.H\n",
    "T = len(trajectories)\n",
    "\n",
    "# Collect trimmed, low-rank approx, empirical transition matrices\n",
    "transition_matrices_before = []\n",
    "transition_matrices = []\n",
    "for a in range(A):\n",
    "    # Collect empirical transition matrices\n",
    "    transition_matrix_a = np.zeros([n, n])\n",
    "    visitations_a = np.zeros([n])\n",
    "    for x in tqdm(range(n)):\n",
    "        visitations_a[x] = count_visitation(x, a, trajectories)\n",
    "        for y in range(n):\n",
    "            transition_matrix_a[x, y] = count_transition(x, a, y, trajectories)\n",
    "    # Trimming!\n",
    "    ratio = (T * H) / (n * A)\n",
    "    num_trimmed = int(np.floor(n * np.exp(- ratio * np.log(ratio))))\n",
    "    if num_trimmed > 0:\n",
    "        contexts_ordered = np.argsort(visitations_a)\n",
    "        contexts_trimmed = contexts_ordered[-num_trimmed:]\n",
    "        for x, y in zip(contexts_trimmed, contexts_trimmed):\n",
    "            transition_matrix_a[x][y] = 0\n",
    "\n",
    "    transition_matrices_before.append(transition_matrix_a)\n",
    "    # Low-rank approximation\n",
    "    transition_matrices.append(low_rank(transition_matrix_a, r=S))\n",
    "\n",
    "M_in = np.concatenate(tuple(transition_matrices), axis=1)\n",
    "M_out = np.concatenate(tuple(transition_matrices), axis=0).T\n",
    "M = np.concatenate((M_in, M_out), axis=1)\n",
    "\n",
    "# l1-normalize rows\n",
    "row_sums = M.sum(axis=1)\n",
    "row_sums[row_sums == 0] = 1\n",
    "M = M / row_sums[:, np.newaxis]\n",
    "# M = normalize(M, norm='l1', axis=1)\n",
    "\n",
    "# S-median clustering to the rows\n",
    "initial_medians = M[:S, :]\n",
    "# initial_medians = np.random.randn(S, 2*n*A)\n",
    "kmedians_instance = kmedians(M, initial_medians)\n",
    "kmedians_instance.process()\n",
    "clusters = kmedians_instance.get_clusters()\n",
    "\n",
    "f_1 = {}\n",
    "for x in range(n):\n",
    "    for s in range(S):\n",
    "        if x in clusters[s]:\n",
    "            f_1[x] = s\n",
    "\n",
    "init_err_rate = error_rate(f, f_1, env.n, env.S)\n",
    "print(\"Error rate after initial clustering is \", init_err_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final error rate is  0.5\n",
      "Errors along the improvement steps:  [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# likelihood_improvement\n",
    "n, S, A, H = env.n, env.S, env.A, env.H\n",
    "\n",
    "f_final = f_1\n",
    "# num_iter = int(np.floor(np.log(n * A)))\n",
    "num_iter = 10\n",
    "errors = []\n",
    "fs = []\n",
    "\n",
    "for _ in tqdm(range(num_iter)):\n",
    "    # estimated latent transition matrices\n",
    "    Ns = [np.zeros((S, S)) for _ in range(A)]\n",
    "    for a in range(A):\n",
    "        for s in range(S):\n",
    "            for k in range(S):\n",
    "                Ns[a][s][k] = count_transition_latent(s, a, k, trajectories, f_final)\n",
    "\n",
    "    # likelihood improvement\n",
    "    f_ = {}\n",
    "    for x in range(n):\n",
    "        likelihoods = []\n",
    "        for j in range(S):\n",
    "            # N2 = number of visitations to j\n",
    "            N2 = 0\n",
    "            for a in range(A):\n",
    "                tmp = np.sum(Ns[a], axis=0)\n",
    "                N2 += tmp[j]\n",
    "            likelihood = 0\n",
    "            for a in range(A):\n",
    "                # N1 = number of visitations from (j, a)\n",
    "                tmp = np.sum(Ns[a], axis=1)\n",
    "                N1 = tmp[j]\n",
    "                # degenerate case\n",
    "                if N1 == 0 or N2 == 0:\n",
    "                    likelihood = -inf\n",
    "                else:\n",
    "                    for s in range(S):\n",
    "                        # estimate of p and p_bwd\n",
    "                        p_estimated = Ns[a][j][s] / N1  # ((j, a) -> s) / ((j, a) -> X)\n",
    "                        p_bwd_estimated = Ns[a][s][j] / N2  # (j <- (s, a)) / (j <- X)\n",
    "                        if p_estimated == 0 or p_bwd_estimated == 0:\n",
    "                            likelihood = -inf\n",
    "                            continue\n",
    "                        # number of visitations (x, a) -> s\n",
    "                        N3 = count_transition_mixed1(x, a, s, trajectories, f_final)\n",
    "                        # number of visitations (s, a) -> x\n",
    "                        N4 = count_transition_mixed2(s, a, x, trajectories, f_final)\n",
    "\n",
    "                        # compute likelihood\n",
    "                        likelihood += (N3 * np.log(p_estimated)) + (N4 * np.log(p_bwd_estimated))\n",
    "            likelihoods.append(likelihood)\n",
    "        # new cluster\n",
    "        # print(likelihoods)\n",
    "        f_[x] = np.argmax(likelihoods)\n",
    "        fs.append(f_)\n",
    "    f_final = f_\n",
    "    errors.append(error_rate(f, f_final, env.n, env.S))\n",
    "\n",
    "\n",
    "# likelihood_improvement\n",
    "# final_err_rate = error_rate(f, f_1, env.n, env.S)\n",
    "print(\"Final error rate is \", errors[-1])\n",
    "print(\"Errors along the improvement steps: \", errors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[-inf, -inf]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihoods"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}